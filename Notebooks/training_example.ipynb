{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f453f5",
   "metadata": {},
   "source": [
    "# Full Test of imported model\n",
    "\n",
    "Here we run through a full test of the imported model, including loading the model, defining the input data, and running the model to get the output. We will also include some additional checks to ensure the model is working correctly. This is a hard task to train on and it's worth noting that the model will not appear to be working correctly AT ALL. \n",
    "\n",
    "In order to convince you that the model is actually working, try out the blinking dataset, which has neurons that are blinking at different frequencies. Furthermore if you believe that the problem is that the model does diffusion, there is a secret ```disable_diffusion``` flag that you can use to disable the diffusion process. I don't want people shooting themselves in the foot so the flag must be enabled manually after a ```DifusssionWrapper``` is instantiated.\n",
    "\n",
    "Disabling Weights and Biases logging requires setting it to false in ```prepare_data_and_model``` and ```train_epoch```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573adca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sandman.data_loading.data_loader_map import make_map_loader\n",
    "from sandman.data_loading.chaotic_rnn_loader import make_chaotic_rnn_loader\n",
    "from sandman.data_loading.blinking import make_blinking_toy_loader\n",
    "from sandman.paths import DATA_DIR\n",
    "\n",
    "from sandman.models.training import train_epoch, prepare_data_and_model\n",
    "\n",
    "from sandman.models.utils import TargetSpec, MaskingPolicy\n",
    "from sandman.models.utils import SpikeCountTarget, mask_one_region_policy, SpikeCountMSETarget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b3c61",
   "metadata": {},
   "source": [
    "### Dataset Loading\n",
    "Only uncomment one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================== Import of MAP data loading\n",
    "\n",
    "# session_order = pickle.load(open(DATA_DIR / \"tables_and_infos/session_order.pkl\", \"rb\"))\n",
    "# eids = np.sort(session_order[:5]) # originall :40\n",
    "# print(\"Using eids:\", eids)\n",
    "\n",
    "# data_loader, num_neurons, datasets, areaoi_ind, area_ind_list_list, heldout_info_list, trial_type_dict = make_map_loader(\n",
    "#     eids,\n",
    "#     batch_size=2,\n",
    "#     include_opto=False\n",
    "# )\n",
    "\n",
    "#========================== Import of Chaotic RNN data loading\n",
    "\n",
    "# eids = np.arange(5)\n",
    "# data_loader, num_neurons, _, area_ind_list_list, record_info_list = make_chaotic_rnn_loader(\n",
    "#     eids,\n",
    "#     batch_size=1,\n",
    "# )\n",
    "\n",
    "#========================== Import of Blinking Toy data loading\n",
    "\n",
    "data_loader = make_blinking_toy_loader(T=100, batch_size=1, device=\"mps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c7f46e",
   "metadata": {},
   "source": [
    "### Training/Model Objective!\n",
    "\n",
    "I'm proud of these. This is a generalization of the neural activation modelling process. Play around with the multitude I made in the ```sandman.models.utils``` module. Make your own too! They only take a couple of lines to make!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9045fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = SpikeCountMSETarget()\n",
    "masking_policy = mask_one_region_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de52067",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "Good luck! It's tough to make something that works well. You are going to have a lot of ```n_neurons x d_model``` matrices for encoding and decoding so parameter count is mostly dependent on ```d_model```. Don't let it drop below 16 or it will fundementally break RoPE embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5e84bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoah\u001b[0m to \u001b[32mhttp://localhost:8080\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/noah/Desktop/courses/8201/Sandman/tests/wandb/run-20251217_031251-jyi222i9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='http://localhost:8080/noah/sandman-diffusion/runs/jyi222i9' target=\"_blank\">region_diffusion_poisson</a></strong> to <a href='http://localhost:8080/noah/sandman-diffusion' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='http://localhost:8080/noah/sandman-diffusion' target=\"_blank\">http://localhost:8080/noah/sandman-diffusion</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='http://localhost:8080/noah/sandman-diffusion/runs/jyi222i9' target=\"_blank\">http://localhost:8080/noah/sandman-diffusion/runs/jyi222i9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1.10 million parameters.\n"
     ]
    }
   ],
   "source": [
    "model_args = {\n",
    "    \"d_model\": 32,\n",
    "    \"n_layers\": 8,\n",
    "    \"n_heads\": 4,\n",
    "    'encoder_n_heads': 2\n",
    "}\n",
    "\n",
    "noise_scheduler_args = {\n",
    "    \"num_train_timesteps\": 20,\n",
    "    \"beta_start\": 1e-4,\n",
    "    \"beta_end\": 0.02,\n",
    "    \"beta_schedule\": \"linear\",\n",
    "}\n",
    "\n",
    "diffusion, optimizer, lr_scheduler, accelerator, data_loader = prepare_data_and_model(\n",
    "    data_loader=data_loader,\n",
    "    model_args=model_args,\n",
    "    noise_scheduler_args=noise_scheduler_args,\n",
    "    max_epochs=100,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    target_spec=target,\n",
    "    masking_policy=masking_policy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ea38ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 8])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(data_loader[\"train\"]))\n",
    "print(sample_batch['spikes_data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6717b0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120583f8d2e94090ae5f5d1fc6910e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.2818349611312151\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(\n",
    "        loader=data_loader[\"train\"],\n",
    "        diffusion=diffusion,\n",
    "        optimizer=optimizer,\n",
    "        accelerator=accelerator,\n",
    "        epoch=epoch,\n",
    "        log_every=50 # Lots of logging for debugging purposes\n",
    "    )\n",
    "    print(f\"Epoch {epoch} train loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eff0d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sandman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
